#!/usr/bin/env python3
"""
åœ°å±‚åˆ†å±‚å­—å…¸å¯è§†åŒ–ç¼–è¾‘å·¥å…· - FlaskæœåŠ¡å™¨

æ­¤è„šæœ¬å¯åŠ¨åœ°å±‚åˆ†å±‚å­—å…¸çš„WebæœåŠ¡ï¼Œæ”¯æŒæ•°æ®é¢„åŠ è½½å’Œå¯è§†åŒ–ç¼–è¾‘ã€‚
è„šæœ¬è·¯å¾„ç›¸å¯¹äºæŠ€èƒ½æ ¹ç›®å½•è¿è¡Œï¼Œç¡®ä¿è·¨å¹³å°å…¼å®¹æ€§ã€‚
"""

from flask import Flask, request, jsonify, send_from_directory
import pandas as pd
import os
import json
import webbrowser
import threading
import time
import argparse
from werkzeug.utils import secure_filename

# ç¡®å®šæŠ€èƒ½æ ¹ç›®å½•ï¼ˆè„šæœ¬ä½äº scripts/ å­ç›®å½•ä¸­ï¼‰
SCRIPT_DIR = os.path.dirname(os.path.abspath(__file__))
SKILL_ROOT = os.path.dirname(SCRIPT_DIR)
ASSETS_DIR = os.path.join(SKILL_ROOT, 'assets')

# uploadsç›®å½•ï¼šä¼˜å…ˆä½¿ç”¨å½“å‰å·¥ä½œç›®å½•ä¸‹çš„uploadsï¼Œä¾¿äºç”¨æˆ·è®¿é—®
UPLOADS_DIR = os.path.join(os.getcwd(), 'uploads')

# åˆå§‹åŒ–Flaskåº”ç”¨
app = Flask(__name__)
app.config['UPLOAD_FOLDER'] = UPLOADS_DIR
app.config['MAX_CONTENT_LENGTH'] = 16 * 1024 * 1024  # 16MB max file size

# ç¡®ä¿ä¸Šä¼ ç›®å½•å­˜åœ¨
os.makedirs(app.config['UPLOAD_FOLDER'], exist_ok=True)

# å…è®¸çš„æ–‡ä»¶æ‰©å±•å
ALLOWED_EXTENSIONS = {'csv'}

def allowed_file(filename):
    return '.' in filename and \
           filename.rsplit('.', 1)[1].lower() in ALLOWED_EXTENSIONS

@app.route('/')
def index():
    """æä¾›ä¸»é¡µé¢"""
    return send_from_directory(ASSETS_DIR, 'stratigraphic_visualizer.html')

@app.route('/<path:filename>')
def serve_static(filename):
    """æä¾›é™æ€æ–‡ä»¶æœåŠ¡"""
    return send_from_directory(ASSETS_DIR, filename)

@app.route('/api/upload', methods=['POST'])
def upload_file():
    try:
        # å¦‚æœæœ‰é¢„åŠ è½½æ•°æ®ï¼Œç›´æ¥è¿”å›
        if PRELOADED_DATA:
            file_strat_list = [item['æ‰€å±å±‚ä½'] for item in PRELOADED_DATA]
            
            # æ•´åˆåœ°å±‚é¡ºåºï¼šä½¿ç”¨é¢„è®¾é¡ºåºï¼ˆå¦‚æœå­˜åœ¨ï¼‰ï¼Œå¹¶è¡¥å……æ–‡ä»¶ä¸­å‡ºç°ä½†ä¸åœ¨é¢„è®¾é¡ºåºä¸­çš„å±‚ä½
            if STRATIGRAPHY_ORDER:
                final_strat_list = list(STRATIGRAPHY_ORDER)
                for strat in file_strat_list:
                    if strat not in final_strat_list:
                        final_strat_list.append(strat)
            else:
                final_strat_list = file_strat_list

            stratigraphy_data = [{'åœ°å±‚ä¿¡æ¯': name, 'åºå·': i+1} for i, name in enumerate(final_strat_list)]

            return jsonify({
                'success': True,
                'data': PRELOADED_DATA,
                'stratigraphy': stratigraphy_data,
                'reference_order': STRATIGRAPHY_ORDER,
                'filename': PRELOADED_FILENAME,
                'record_count': len(PRELOADED_DATA),
                'preloaded': True
            })
        
        # å¦åˆ™å¤„ç†ä¸Šä¼ çš„æ–‡ä»¶
        if 'file' not in request.files:
            return jsonify({'error': 'No file part'}), 400
        
        file = request.files['file']
        
        if file.filename == '':
            return jsonify({'error': 'No selected file'}), 400
        
        if file and allowed_file(file.filename):
            filename = secure_filename(file.filename)
            filepath = os.path.join(app.config['UPLOAD_FOLDER'], filename)
            file.save(filepath)
            
            # è¯»å–CSVæ–‡ä»¶
            df = pd.read_csv(filepath, encoding='utf-8-sig')
            
            # éªŒè¯å¿…è¦çš„åˆ—æ˜¯å¦å­˜åœ¨
            required_columns = ['åœ°å±‚åç§°', 'æ‰€å±å±‚ä½', 'é¡¶ç•Œæ‰€å¤„ä½ç½®ï¼ˆ0~1ï¼‰', 'åº•ç•Œæ‰€å¤„ä½ç½®ï¼ˆ0~1ï¼‰']
            missing_columns = [col for col in required_columns if col not in df.columns]
            
            if missing_columns:
                return jsonify({'error': f'Missing required columns: {missing_columns}'}), 400
            
            # å°†æ•°æ®è½¬æ¢ä¸ºå­—å…¸æ ¼å¼è¿”å›
            data = df.to_dict('records')
            
            # è·å–å”¯ä¸€å±‚ä½ä¿¡æ¯ç”¨äºæ„å»ºå±‚çº§ç»“æ„
            file_strat_list = df['æ‰€å±å±‚ä½'].drop_duplicates().tolist()

            # æ•´åˆåœ°å±‚é¡ºåºï¼šä½¿ç”¨é¢„è®¾é¡ºåºï¼ˆå¦‚æœå­˜åœ¨ï¼‰ï¼Œå¹¶è¡¥å……æ–‡ä»¶ä¸­å‡ºç°ä½†ä¸åœ¨é¢„è®¾é¡ºåºä¸­çš„å±‚ä½
            if STRATIGRAPHY_ORDER:
                final_strat_list = list(STRATIGRAPHY_ORDER)
                for strat in file_strat_list:
                    if strat not in final_strat_list:
                        final_strat_list.append(strat)
            else:
                final_strat_list = file_strat_list

            stratigraphy_data = [{'åœ°å±‚ä¿¡æ¯': name, 'åºå·': i+1} for i, name in enumerate(final_strat_list)]

            return jsonify({
                'success': True,
                'data': data,
                'stratigraphy': stratigraphy_data,
                'reference_order': STRATIGRAPHY_ORDER,
                'filename': filename,
                'record_count': len(data),
                'preloaded': False
            })
        else:
            return jsonify({'error': 'Invalid file type. Only CSV files are allowed.'}), 400
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/api/export', methods=['POST'])
def export_data():
    try:
        data = request.json.get('data', [])
        original_filename = request.json.get('original_filename', '')
        
        if not data:
            return jsonify({'error': 'No data provided'}), 400
        
        # å°†æ•°æ®è½¬æ¢ä¸ºDataFrame
        df = pd.DataFrame(data)
        
        # ç¡®ä¿åˆ—æŒ‰æŒ‡å®šé¡ºåºæ’åˆ—ï¼šåœ°å±‚åç§°ï¼Œæ‰€å±å±‚ä½ï¼Œé¡¶ç•Œæ‰€å¤„ä½ç½®ï¼ˆ0~1ï¼‰ï¼Œåº•ç•Œæ‰€å¤„ä½ç½®ï¼ˆ0~1ï¼‰
        required_columns = ['åœ°å±‚åç§°', 'æ‰€å±å±‚ä½', 'é¡¶ç•Œæ‰€å¤„ä½ç½®ï¼ˆ0~1ï¼‰', 'åº•ç•Œæ‰€å¤„ä½ç½®ï¼ˆ0~1ï¼‰']
        
        # æ£€æŸ¥DataFrameæ˜¯å¦åŒ…å«æ‰€éœ€çš„æ‰€æœ‰åˆ—
        missing_columns = [col for col in required_columns if col not in df.columns]
        if missing_columns:
            return jsonify({'error': f'Missing required columns: {missing_columns}'}), 400
        
        # åªé€‰æ‹©å¹¶é‡æ–°æ’åºæ‰€éœ€çš„åˆ—
        df = df[required_columns]
        
        # å¯¹æ•°å€¼åˆ—è¿›è¡Œæ ¼å¼åŒ–ï¼Œä¿ç•™ä¸¤ä½å°æ•°
        numeric_columns = ['é¡¶ç•Œæ‰€å¤„ä½ç½®ï¼ˆ0~1ï¼‰', 'åº•ç•Œæ‰€å¤„ä½ç½®ï¼ˆ0~1ï¼‰']
        for col in numeric_columns:
            if col in df.columns:
                df[col] = df[col].round(2)
        
        # ç”Ÿæˆå¯¼å‡ºæ–‡ä»¶åï¼šåŸæ–‡ä»¶ååŠ verificationåç¼€
        if original_filename:
            # ç§»é™¤åŸæ–‡ä»¶çš„æ‰©å±•å
            name_without_ext = os.path.splitext(original_filename)[0]
            export_filename = f"{name_without_ext}_verification.csv"
        else:
            # å¦‚æœæ²¡æœ‰åŸæ–‡ä»¶åï¼Œä½¿ç”¨é»˜è®¤åç§°
            export_filename = "export_verification.csv"
        
        filepath = os.path.join(app.config['UPLOAD_FOLDER'], export_filename)
        
        # ä¿å­˜ä¸ºCSVæ–‡ä»¶
        df.to_csv(filepath, index=False, encoding='utf-8-sig')
        
        return jsonify({
            'success': True,
            'filename': export_filename,
            'download_url': f'/download/{export_filename}'
        })
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/download/<filename>')
def download_file(filename):
    return send_from_directory(app.config['UPLOAD_FOLDER'], filename, as_attachment=True)

# å…¨å±€å˜é‡å­˜å‚¨é¢„åŠ è½½æ•°æ®
PRELOADED_DATA = None
PRELOADED_FILENAME = None

# åœ°å±‚åˆ†å±‚å‚è€ƒæ•°æ®ï¼ˆé»˜è®¤ä¸ºç©ºï¼Œé€šè¿‡å‘½ä»¤è¡Œå‚æ•°åŠ è½½ï¼‰
STRATIGRAPHY_ORDER = []

def resolve_path(filepath):
    """
    è§£ææ–‡ä»¶è·¯å¾„ï¼Œæ”¯æŒç›¸å¯¹è·¯å¾„å’Œç»å¯¹è·¯å¾„
    
    è§„åˆ™ï¼š
    - ç»å¯¹è·¯å¾„ç›´æ¥ä½¿ç”¨
    - ç›¸å¯¹è·¯å¾„åŸºäºå½“å‰å·¥ä½œç›®å½•è§£æ
    """
    if not filepath:
        return None
    
    if os.path.isabs(filepath):
        return filepath
    
    # ç›¸å¯¹è·¯å¾„ï¼šåŸºäºå½“å‰å·¥ä½œç›®å½•
    return os.path.join(os.getcwd(), filepath)


def load_stratigraphy_reference(filepath):
    """åŠ è½½åœ°å±‚åˆ†å±‚å‚è€ƒæ–‡ä»¶"""
    global STRATIGRAPHY_ORDER
    
    filepath = resolve_path(filepath)
    
    if not filepath or not os.path.exists(filepath):
        print(f"âŒ åœ°å±‚åˆ†å±‚å‚è€ƒæ–‡ä»¶ä¸å­˜åœ¨: {filepath}")
        return False
    
    try:
        df = pd.read_csv(filepath, encoding='utf-8-sig')
        
        # éªŒè¯å¿…è¦çš„åˆ—æ˜¯å¦å­˜åœ¨
        required_column = 'åœ°å±‚ä¿¡æ¯'
        if required_column not in df.columns:
            print(f"âŒ æ–‡ä»¶ç¼ºå°‘å¿…è¦åˆ—: {required_column}")
            return False
        
        STRATIGRAPHY_ORDER = df[required_column].tolist()
        print(f"âœ… å·²åŠ è½½åœ°å±‚åˆ†å±‚å‚è€ƒæ–‡ä»¶: {os.path.basename(filepath)} ({len(STRATIGRAPHY_ORDER)} ä¸ªåœ°å±‚)")
        return True
        
    except Exception as e:
        print(f"âŒ åŠ è½½åœ°å±‚åˆ†å±‚å‚è€ƒæ–‡ä»¶å¤±è´¥: {e}")
        return False

def preload_data(filepath):
    """é¢„åŠ è½½åœ°å±‚æ•°æ®æ–‡ä»¶"""
    global PRELOADED_DATA, PRELOADED_FILENAME
    
    filepath = resolve_path(filepath)
    
    if not filepath or not os.path.exists(filepath):
        print(f"âŒ æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {filepath}")
        return False
    
    try:
        df = pd.read_csv(filepath, encoding='utf-8-sig')
        
        # éªŒè¯å¿…è¦çš„åˆ—æ˜¯å¦å­˜åœ¨
        required_columns = ['åœ°å±‚åç§°', 'æ‰€å±å±‚ä½', 'é¡¶ç•Œæ‰€å¤„ä½ç½®ï¼ˆ0~1ï¼‰', 'åº•ç•Œæ‰€å¤„ä½ç½®ï¼ˆ0~1ï¼‰']
        missing_columns = [col for col in required_columns if col not in df.columns]
        
        if missing_columns:
            print(f"âŒ æ–‡ä»¶ç¼ºå°‘å¿…è¦åˆ—: {missing_columns}")
            return False
        
        # å°†æ•°æ®è½¬æ¢ä¸ºå­—å…¸æ ¼å¼
        PRELOADED_DATA = df.to_dict('records')
        PRELOADED_FILENAME = os.path.basename(filepath)
        
        print(f"âœ… å·²é¢„åŠ è½½æ•°æ®æ–‡ä»¶: {PRELOADED_FILENAME} ({len(PRELOADED_DATA)} æ¡è®°å½•)")
        return True
        
    except Exception as e:
        print(f"âŒ åŠ è½½æ•°æ®æ–‡ä»¶å¤±è´¥: {e}")
        return False

def reorder_stratigraphy_by_reference(stratigraphy_list, reference_order=STRATIGRAPHY_ORDER):
    """
    æ ¹æ®å‚è€ƒé¡ºåºé‡æ–°æ’åˆ—åœ°å±‚åˆ—è¡¨
    """
    if not reference_order:
        return stratigraphy_list
    
    # åˆ›å»ºä¸€ä¸ªå­—å…¸ï¼Œç”¨äºå¿«é€ŸæŸ¥æ‰¾å‚è€ƒé¡ºåºä¸­çš„ç´¢å¼•
    order_map = {item: idx for idx, item in enumerate(reference_order)}
    
    # åˆ†ç¦»åœ¨å‚è€ƒé¡ºåºä¸­å­˜åœ¨çš„å’Œä¸å­˜åœ¨çš„åœ°å±‚
    in_reference = []
    not_in_reference = []
    
    for item in stratigraphy_list:
        if item in order_map:
            in_reference.append((order_map[item], item))
        else:
            not_in_reference.append(item)
    
    # æŒ‰ç…§å‚è€ƒé¡ºåºå¯¹å­˜åœ¨çš„åœ°å±‚æ’åº
    in_reference.sort(key=lambda x: x[0])
    in_reference = [item[1] for item in in_reference]
    
    # åˆå¹¶ç»“æœï¼šå‚è€ƒé¡ºåºä¸­çš„åœ°å±‚ + ä¸åœ¨å‚è€ƒé¡ºåºä¸­çš„åœ°å±‚
    result = in_reference + not_in_reference
    
    return result

@app.route('/api/process', methods=['POST'])
def process_stratigraphy():
    """å¤„ç†åœ°å±‚æ•°æ®ï¼Œè¿”å›å±‚çº§ç»“æ„"""
    try:
        data = request.json.get('data', [])
        
        if not data:
            return jsonify({'error': 'No data provided'}), 400
        
        # åˆ›å»ºDataFrame
        df = pd.DataFrame(data)
        
        # æ„å»ºå±‚çº§ç»“æ„
        hierarchy = {}
        if 'æ‰€å±å±‚ä½' in df.columns and 'åœ°å±‚åç§°' in df.columns:
            hierarchy = df.groupby('æ‰€å±å±‚ä½')['åœ°å±‚åç§°'].apply(list).to_dict()
        
        # è·å–æ‰€æœ‰å”¯ä¸€çš„åœ°å±‚åç§°åŠå®ƒä»¬çš„é¢œè‰²
        formations = df['åœ°å±‚åç§°'].drop_duplicates().tolist()
        
        # è·å–å”¯ä¸€å±‚ä½ä¿¡æ¯å¹¶æ ¹æ®å‚è€ƒé¡ºåºé‡æ–°æ’åˆ—
        stratigraphy_list = df['æ‰€å±å±‚ä½'].drop_duplicates().tolist()
        ordered_stratigraphy_list = reorder_stratigraphy_by_reference(stratigraphy_list)
        
        return jsonify({
            'success': True,
            'hierarchy': hierarchy,
            'formations': formations,
            'stratigraphy_list': ordered_stratigraphy_list
        })
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/api/load_stratigraphy_order', methods=['GET'])
def load_stratigraphy_order():
    """è·å–é¢„è®¾çš„åœ°å±‚é¡ºåº"""
    try:
        return jsonify({
            'success': True,
            'stratigraphy_order': STRATIGRAPHY_ORDER
        })
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/api/upload_stratigraphy_reference', methods=['POST'])
def upload_stratigraphy_reference():
    """ä¸Šä¼ åœ°å±‚åˆ†å±‚å‚è€ƒæ–‡ä»¶"""
    try:
        if 'file' not in request.files:
            return jsonify({'error': 'No file part'}), 400
        
        file = request.files['file']
        
        if file.filename == '':
            return jsonify({'error': 'No selected file'}), 400
        
        if file and allowed_file(file.filename):
            filename = secure_filename(file.filename)
            filepath = os.path.join(app.config['UPLOAD_FOLDER'], filename)
            file.save(filepath)
            
            # è¯»å–CSVæ–‡ä»¶
            df = pd.read_csv(filepath, encoding='utf-8-sig')
            
            # éªŒè¯å¿…è¦çš„åˆ—æ˜¯å¦å­˜åœ¨
            required_column = 'åœ°å±‚ä¿¡æ¯'
            if required_column not in df.columns:
                return jsonify({'error': f'Missing required column: {required_column}'}), 400
            
            # æ›´æ–°å…¨å±€åœ°å±‚é¡ºåº
            global STRATIGRAPHY_ORDER
            STRATIGRAPHY_ORDER = df[required_column].tolist()
            
            return jsonify({
                'success': True,
                'message': 'åœ°å±‚åˆ†å±‚å‚è€ƒæ–‡ä»¶ä¸Šä¼ æˆåŠŸ',
                'stratigraphy_order': STRATIGRAPHY_ORDER,
                'record_count': len(STRATIGRAPHY_ORDER)
            })
        else:
            return jsonify({'error': 'Invalid file type. Only CSV files are allowed.'}), 400
    except Exception as e:
        return jsonify({'error': str(e)}), 500

def open_browser():
    """å»¶è¿Ÿæ‰“å¼€æµè§ˆå™¨"""
    time.sleep(1.5)  # ç­‰å¾…æœåŠ¡å™¨å¯åŠ¨
    webbrowser.open('http://127.0.0.1:5000')

def start_server(host='127.0.0.1', port=5000, debug=False, stratigraphy_file=None, data_file=None):
    """å¯åŠ¨åœ°å±‚åˆ†å±‚å­—å…¸æœåŠ¡å™¨"""
    print(f"ğŸš€ å¯åŠ¨åœ°å±‚åˆ†å±‚å­—å…¸æœåŠ¡...")
    print(f"ğŸ“ æœåŠ¡åœ°å€: http://{host}:{port}")
    print(f"ğŸ“ ä¸Šä¼ ç›®å½•: {os.path.abspath(app.config['UPLOAD_FOLDER'])}")
    
    # å¦‚æœæŒ‡å®šäº†åœ°å±‚åˆ†å±‚å‚è€ƒæ–‡ä»¶ï¼Œå…ˆåŠ è½½
    if stratigraphy_file:
        print(f"ğŸ“‚ åŠ è½½åœ°å±‚åˆ†å±‚å‚è€ƒæ–‡ä»¶: {stratigraphy_file}")
        if not load_stratigraphy_reference(stratigraphy_file):
            print("âš ï¸  åœ°å±‚åˆ†å±‚å‚è€ƒæ–‡ä»¶åŠ è½½å¤±è´¥ï¼ŒæœåŠ¡å°†ä»¥æ— å‚è€ƒæ¨¡å¼å¯åŠ¨")
    
    # å¦‚æœæŒ‡å®šäº†æ•°æ®æ–‡ä»¶ï¼Œé¢„åŠ è½½æ•°æ®
    if data_file:
        print(f"ğŸ“‚ é¢„åŠ è½½æ•°æ®æ–‡ä»¶: {data_file}")
        if not preload_data(data_file):
            print("âš ï¸  æ•°æ®æ–‡ä»¶é¢„åŠ è½½å¤±è´¥ï¼ŒæœåŠ¡å°†ä»¥æ­£å¸¸æ¨¡å¼å¯åŠ¨")
    
    # åœ¨åå°çº¿ç¨‹ä¸­æ‰“å¼€æµè§ˆå™¨
    threading.Thread(target=open_browser, daemon=True).start()
    
    try:
        app.run(debug=debug, host=host, port=port)
    except KeyboardInterrupt:
        print("\nğŸ‘‹ æœåŠ¡å·²åœæ­¢")
    except Exception as e:
        print(f"âŒ å¯åŠ¨å¤±è´¥: {e}")

def main():
    """ä¸»å‡½æ•°ï¼Œå¤„ç†å‘½ä»¤è¡Œå‚æ•°"""
    parser = argparse.ArgumentParser(description='åœ°å±‚åˆ†å±‚å­—å…¸å¯è§†åŒ–ç¼–è¾‘å·¥å…·')
    parser.add_argument('--host', default='127.0.0.1', help='æœåŠ¡å™¨åœ°å€ (é»˜è®¤: 127.0.0.1)')
    parser.add_argument('--port', type=int, default=5000, help='æœåŠ¡å™¨ç«¯å£ (é»˜è®¤: 5000)')
    parser.add_argument('--debug', action='store_true', help='å¯ç”¨è°ƒè¯•æ¨¡å¼')
    parser.add_argument('-m', '--stratigraphy', help='åœ°å±‚åˆ†å±‚å‚è€ƒCSVæ–‡ä»¶è·¯å¾„ (åŒ…å«åœ°å±‚ä¿¡æ¯åˆ—)')
    parser.add_argument('-d', '--data', help='é¢„åŠ è½½çš„åœ°å±‚æ•°æ®CSVæ–‡ä»¶è·¯å¾„ (åŒ…å«åœ°å±‚åç§°ã€æ‰€å±å±‚ä½ç­‰åˆ—)')
    
    args = parser.parse_args()
    
    # å¯åŠ¨æœåŠ¡å™¨
    start_server(host=args.host, port=args.port, debug=args.debug, 
                stratigraphy_file=args.stratigraphy, data_file=args.data)

if __name__ == '__main__':
    main()
